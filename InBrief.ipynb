{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Brief Notes\n",
    "\n",
    "This notebook will give a quick summary of all the material in the chapters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Basic concepts of Bayes\n",
    "\n",
    "* Backward looking - exploratory data analysis (descriptive stats, visualisation)\n",
    "* Forward looking - Inferential stats\n",
    "\n",
    "Here we us IS methods, and then EDA to summarise, interpret, check, communicate results\n",
    "\n",
    "Generating data is a **stochastic process**, there is always uncertainty involved.\n",
    "\n",
    "Bayes has 3 steps\n",
    "1. Design model by combining prob dists like legos\n",
    "2. use Bayes Theorem to condition (combine model with data)\n",
    "3. Critisise the model\n",
    "\n",
    "Some basic stuff on probabilities, should be familiar by now. To summarise\n",
    "\n",
    "> Probablities are used to measure the uncertainty we have about parameters and Bayes' theorem is the mechanism to correctly update those probabilities in light of new data, hopefully reducing our uncertainty.\n",
    "\n",
    "You can use Kruschke diagrams to reprsent models.\n",
    "\n",
    "The Posterior is the outcome of Bayes' theorem. Usually this is what you report on, giving various averages and spreads.\n",
    "\n",
    "The Highest Posterior Density (HPD) is common. It's the shortest possible interval of the x-axis which contains X% of the the probability density. It allows you to make a statement like 'we think the parameter theta is between 2 and 5, with a probability of 0.95'. Don't confuse this with a confidence interval\n",
    "\n",
    "You can use the posterior to generate the **posterior predictive**. You can then use this to conduct **posterior predictive checks**, PPCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: PyMC3 (and arViz)\n",
    "\n",
    "PyMC3 is a Probablistic Programming Language - a language to create models and run inference on them with numerical analysis. An *Inference Button*\n",
    "\n",
    "A typical pattern\n",
    "1. specify your paramters\n",
    "2. specify your likelyhood and pass it your data\n",
    "3. create a trace with `sample`\n",
    "4. do an arviz `plot_trace` and `summary` on the trace\n",
    "5. plot posterior with HPD with `az.plot_posterior`\n",
    "\n",
    "**Region of practical equivalence (ROPE)** is an interval you choose that you consider important (you might say a coin should be considered fair if its probability of coming up heads is betweeb 0.45 and 0.55). You can compare your HPD with your ROPE to judge your posterior.\n",
    "\n",
    "**Loss functions** are another way to make analyse the posterior. The idea is to capture how different are the true parameter value and the estimated value are. A larger loss function means a worse estimation.\n",
    "\n",
    "The Gaussian is useful because of the CLT. But the Gaussian can be over sensitive to outliers. It can be desentitised using Students T (where the DOF parameter is also assigned a prior).\n",
    "\n",
    ">***No notes from comparing groups, effect size and hierarchical models and shrinkage - sure I did this?!?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Linear Regression\n",
    "\n",
    "Data in the form of pairs of observations: $\\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\\}$.\n",
    "\n",
    "If x and y are both 1d lists, then you have **Simple Linear Regression**\n",
    "\n",
    "If x is multidimensional you have **Multiple Linear Regression**\n",
    "\n",
    "### Simple linear regression\n",
    "$y_i = \\alpha + x_i \\beta$ is the core of LinReg - the expression of 'linear' relationship between x and y. The goal is to estimate the params alpha and beta. A traditional method is by least squares fitting. Another (used here) is generating a probablistic model. \n",
    "\n",
    "$y \\sim N\\left(\\mu = \\alpha + x\\beta, \\epsilon\\right)$, where alpha and beta are normal and epsilon is half cauchy or uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these models alpha and beta tend to be highly correlated (*autocorrelated*). This is a logical consequence of the method, because effectively what you are doing is finding the 'center' of the data, and drawing a line through it. If you think what  happens to the slope and y intercept when you do this, it's easy to see that movements in alpha and beta must be correllated. A way to get around this is to make sure your x data is centered around the mean, so the line you draw through the data will always cross the y axis at around the same value.\n",
    "\n",
    "**Correlation coefficients** measure the degree of linear dependence between two variables, how closely the two ca. The *Pearson*, r, is common. for linear regression, the *coefficient of determinaton* is r^2.\n",
    "\n",
    "You can estimate r by the formula\n",
    "\n",
    "$$r = \\beta \\frac{\\sigma_x}{\\sigma_y}$$\n",
    "\n",
    "You can estimate the pearson by estimating the values in the co-variance matrix.\n",
    "\n",
    "$$\\Sigma = \\begin{bmatrix}\n",
    "    \\sigma_{x1}^2 & \\rho\\sigma_{x1}\\sigma_{x2} \\\\\n",
    "    \\rho\\sigma_{x1}\\sigma_{x2} & \\sigma_{x2}^2 \n",
    "    \\end{bmatrix}$$\n",
    "    \n",
    "where $\\rho$ is the pearson correlation coefficient between the two variables (you would have one rho for each pair of variables)\n",
    "\n",
    "To esimate this in PyMC3 you would use as your likelihood a Multivariate Normal\n",
    "\n",
    "$y \\sim MvN(\\mu, \\Sigma)$\n",
    "\n",
    "$\\mu \\sim N([\\bar{x},\\bar{y}], 10)$\n",
    "\n",
    "$\\sigma_1 \\sim HalfN(10)$\n",
    "\n",
    "$\\sigma_2 \\sim HalfN(10)$\n",
    "\n",
    "$\\rho \\sim U(-1,1)$\n",
    "\n",
    "As with single variable problems, you can use Student T in place of Normal to desensitize\n",
    "\n",
    "As with single variable problems, you can create hierarchical models with hyper-priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Linear Regression\n",
    "Simple linear regression fits a straight line $\\alpha + \\beta x$. Polynomial lin reg looks at higher order equations, i.e. curves, generalising the formula to\n",
    "\n",
    "$$\\mu = \\beta_0 x^0 + \\beta_1 x^1 + \\dots + \\beta_m x^m$$\n",
    "\n",
    "The modelling is basically the same as simple linear regression - you just have more parameters (more $\\beta$'s). The interpretation is not so simple as slope and y-intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple linear regression\n",
    "So far we've looked at an x and y pair, where we want to use x to predict y. Call x your independent variable, IV, y your dependent variable, DV.\n",
    "\n",
    "If your model has several IVs, you have **multiple lin reg**. if you have several DVs it's **multivariate lin reg**.\n",
    "\n",
    "$$\\mu = \\beta_1 x_1 + \\dots + \\beta_m x_m = \\sum_{i=1}^n \\beta_i x_i $$\n",
    "\n",
    "From a modelling perspective it just looks like simple LinR, vectorised.\n",
    "\n",
    "Be careful of multicollinearity with multiple LinR - if you have x1, x2 IVs, and y DV, but x1 and x2 are very highly correlated to eachother, then you won't be able to lock down beta1 and beta 2 (they will be *indeterminate*). If x1 and x2 are basically the same then $\\mu = \\beta_1 x_1 + \\beta_2 x_2 = (\\beta_1 + \\beta_2) 2x$, so beta1 can take any real value, as long as beta2 is has an equal and opposite one. In this case you should probably drop one of the IVs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
